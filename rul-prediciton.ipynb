{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjjhkxMZHoR7"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z1GCEs7PiAm"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import math\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import datetime\n",
        "from scipy.stats import linregress\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnYNMS11PiAo"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import NearestNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiM9W3VCPiAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe50a4a-6a87-45c7-d684-e4719d9a03f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtYSPTFFXIl6"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsnFaax0VtPI",
        "outputId": "356ec967-dcd5-4552-cc97-75c7f944cbcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped data for CNN: (25566, 8, 1)\n",
            "Reshaped data for LSTM: (25566, 1, 8)\n",
            "Reshaped data for CNN + LSTM: (25566, 8, 1)\n",
            "Reshaped data for CNN + CBAM: (25566, 8, 1)\n",
            "Reshaped data for CNN + Transformer: (25566, 8, 1)\n",
            "Reshaped data for CNN + CBAM + Transformer: (25566, 8, 1)\n",
            "Reshaped data for LSTM + Transformer: (25566, 1, 8)\n",
            "Reshaped data for CNN + LSTM + Transformer: (25566, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/TA/NEW DATABASE/THESISMLOTL.csv')\n",
        "\n",
        "# Define the features and target\n",
        "features = ['Motor Ampere', 'Frequency', 'Pump Intake Pressure', 'Temperature Motor',\n",
        "            'Output Volt', 'Pump Discharge Pressure', 'Input Voltage', 'Motor Horse Power (HP)']\n",
        "target = 'EST RUL'\n",
        "\n",
        "X = data[features].values\n",
        "y = data[target].values\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for different models\n",
        "# CNN-based models\n",
        "X_train_cnn = X_train_scaled.reshape(-1, 8, 1)\n",
        "X_val_cnn = X_val_scaled.reshape(-1, 8, 1)\n",
        "X_test_cnn = X_test_scaled.reshape(-1, 8, 1)\n",
        "\n",
        "# LSTM-based models\n",
        "X_train_lstm = X_train_scaled.reshape(-1, 1, 8)\n",
        "X_val_lstm = X_val_scaled.reshape(-1, 1, 8)\n",
        "X_test_lstm = X_test_scaled.reshape(-1, 1, 8)\n",
        "\n",
        "# For combined models (e.g., CNN + LSTM, CNN + Transformer, etc.)\n",
        "X_train_cnn_lstm = X_train_cnn\n",
        "X_val_cnn_lstm = X_val_cnn\n",
        "X_test_cnn_lstm = X_test_cnn\n",
        "\n",
        "X_train_cnn_cbam = X_train_cnn\n",
        "X_val_cnn_cbam = X_val_cnn\n",
        "X_test_cnn_cbam = X_test_cnn\n",
        "\n",
        "X_train_cnn_trans = X_train_cnn\n",
        "X_val_cnn_trans = X_val_cnn\n",
        "X_test_cnn_trans = X_test_cnn\n",
        "\n",
        "X_train_cnn_cbam_trans = X_train_cnn\n",
        "X_val_cnn_cbam_trans = X_val_cnn\n",
        "X_test_cnn_cbam_trans = X_test_cnn\n",
        "\n",
        "X_train_lstm_trans = X_train_lstm\n",
        "X_val_lstm_trans = X_val_lstm\n",
        "X_test_lstm_trans = X_test_lstm\n",
        "\n",
        "X_train_cnn_lstm_trans = X_train_cnn\n",
        "X_val_cnn_lstm_trans = X_val_cnn\n",
        "X_test_cnn_lstm_trans = X_test_cnn\n",
        "\n",
        "print('Reshaped data for CNN:', X_train_cnn.shape)\n",
        "print('Reshaped data for LSTM:', X_train_lstm.shape)\n",
        "print('Reshaped data for CNN + LSTM:', X_train_cnn_lstm.shape)\n",
        "print('Reshaped data for CNN + CBAM:', X_train_cnn_cbam.shape)\n",
        "print('Reshaped data for CNN + Transformer:', X_train_cnn_trans.shape)\n",
        "print('Reshaped data for CNN + CBAM + Transformer:', X_train_cnn_cbam_trans.shape)\n",
        "print('Reshaped data for LSTM + Transformer:', X_train_lstm_trans.shape)\n",
        "print('Reshaped data for CNN + LSTM + Transformer:', X_train_cnn_lstm_trans.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "mnclQOapHHrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "k0RmgScuXz2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=16, kernel_size=2, activation='relu', input_shape=(8, 1), padding='same'))\n",
        "    model.add(Conv1D(filters=32, kernel_size=2, activation='relu', padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "cnn_model = create_cnn_model()\n",
        "cnn_model.summary()\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_history = cnn_model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_val_cnn, y_val))\n",
        "\n",
        "# Evaluate the CNN model\n",
        "cnn_mae, cnn_mse = cnn_model.evaluate(X_test_cnn, y_test)\n",
        "cnn_rmse = np.sqrt(cnn_mse)\n",
        "cnn_r2 = 1 - (np.sum((y_test - cnn_model.predict(X_test_cnn).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('CNN Evaluation:')\n",
        "print(f'MAE: {cnn_mae}, MSE: {cnn_mse}, RMSE: {cnn_rmse}, R2: {cnn_r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4er_PWCsZ3Ko",
        "outputId": "a772bc4b-2355-4be9-c028-e36f97d8ba03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 8, 16)             48        \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 32)             1056      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17617 (68.82 KB)\n",
            "Trainable params: 17617 (68.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 6s 6ms/step - loss: 561621.3125 - mae: 501.0003 - val_loss: 455956.0000 - val_mae: 471.8770\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 485593.0938 - mae: 478.1604 - val_loss: 442982.0312 - val_mae: 457.4457\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 472922.3125 - mae: 470.6222 - val_loss: 440064.5000 - val_mae: 470.3068\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 460745.1250 - mae: 463.6748 - val_loss: 428065.4062 - val_mae: 454.4076\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 446972.0312 - mae: 454.4447 - val_loss: 418185.7500 - val_mae: 445.9361\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 433824.3438 - mae: 444.8744 - val_loss: 404393.0625 - val_mae: 427.4540\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 420611.0625 - mae: 436.9265 - val_loss: 393398.3750 - val_mae: 420.7057\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 408736.1250 - mae: 430.9499 - val_loss: 384446.3438 - val_mae: 416.6450\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 395324.8438 - mae: 423.1034 - val_loss: 374914.6250 - val_mae: 419.0416\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 381128.0000 - mae: 415.2298 - val_loss: 364115.8125 - val_mae: 410.1791\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 366763.7500 - mae: 405.4797 - val_loss: 360234.7188 - val_mae: 414.6494\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 354352.5000 - mae: 398.0264 - val_loss: 346744.0938 - val_mae: 400.0660\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 342796.4375 - mae: 390.0001 - val_loss: 333114.4062 - val_mae: 395.2353\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 332466.6250 - mae: 385.2063 - val_loss: 327800.6562 - val_mae: 394.3690\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 322332.8438 - mae: 378.1301 - val_loss: 310195.9375 - val_mae: 368.0215\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 314310.3750 - mae: 372.3415 - val_loss: 305773.0625 - val_mae: 372.7819\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 305208.1250 - mae: 366.7320 - val_loss: 293270.7188 - val_mae: 358.2467\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 295413.5312 - mae: 360.5042 - val_loss: 286605.6250 - val_mae: 363.0287\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 287659.2188 - mae: 355.3106 - val_loss: 275688.7188 - val_mae: 344.2195\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 277456.4688 - mae: 347.4998 - val_loss: 270401.8125 - val_mae: 350.3797\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 269436.9062 - mae: 342.7340 - val_loss: 262643.9688 - val_mae: 331.5865\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 262009.7969 - mae: 335.6206 - val_loss: 254717.1562 - val_mae: 338.3580\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 254170.8125 - mae: 330.1005 - val_loss: 252863.3594 - val_mae: 335.8379\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 247270.0781 - mae: 324.1559 - val_loss: 251317.9688 - val_mae: 331.2375\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 239207.3594 - mae: 316.7099 - val_loss: 231129.2500 - val_mae: 318.8665\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 232726.0312 - mae: 311.8424 - val_loss: 232954.6250 - val_mae: 317.7444\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 228447.4688 - mae: 307.4716 - val_loss: 226382.7031 - val_mae: 313.2783\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 222263.4375 - mae: 302.2328 - val_loss: 216919.8906 - val_mae: 299.0228\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 217359.9219 - mae: 296.8227 - val_loss: 213811.2812 - val_mae: 301.2929\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 212451.2969 - mae: 293.5240 - val_loss: 218092.8594 - val_mae: 306.2859\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 209282.6719 - mae: 289.6753 - val_loss: 200665.0156 - val_mae: 287.8688\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 204412.2188 - mae: 286.1563 - val_loss: 199977.5625 - val_mae: 284.7119\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 200613.8125 - mae: 282.9923 - val_loss: 192381.4531 - val_mae: 284.2186\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 197012.5781 - mae: 280.6810 - val_loss: 197181.9062 - val_mae: 291.4493\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 193048.3750 - mae: 277.8488 - val_loss: 189261.1875 - val_mae: 279.9098\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 191431.3438 - mae: 276.1438 - val_loss: 184319.5781 - val_mae: 277.9456\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 188212.9062 - mae: 274.6615 - val_loss: 176980.2500 - val_mae: 270.0716\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 184691.5938 - mae: 271.9685 - val_loss: 172761.6094 - val_mae: 268.0323\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 181065.2188 - mae: 269.3511 - val_loss: 178977.5000 - val_mae: 276.1074\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 179166.2969 - mae: 268.0771 - val_loss: 176347.2500 - val_mae: 268.4108\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 176824.5312 - mae: 266.2180 - val_loss: 164752.5469 - val_mae: 259.2694\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 174413.4062 - mae: 264.3498 - val_loss: 164407.1719 - val_mae: 259.7512\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 171635.0469 - mae: 261.6973 - val_loss: 175227.8125 - val_mae: 273.7343\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 168733.1406 - mae: 259.5649 - val_loss: 158426.8594 - val_mae: 255.5285\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 166030.1406 - mae: 257.4557 - val_loss: 160944.7969 - val_mae: 260.7961\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 164783.0469 - mae: 257.4413 - val_loss: 154866.9219 - val_mae: 253.9238\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 160892.2344 - mae: 254.5196 - val_loss: 153852.9844 - val_mae: 254.7141\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 159154.8281 - mae: 252.8677 - val_loss: 150723.0781 - val_mae: 252.5358\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 157556.2969 - mae: 252.0925 - val_loss: 145889.5781 - val_mae: 247.4566\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 154055.7188 - mae: 248.6353 - val_loss: 143376.8594 - val_mae: 246.5182\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 144999.3438 - mae: 243.6004\n",
            "172/172 [==============================] - 0s 1ms/step\n",
            "CNN Evaluation:\n",
            "MAE: 144999.34375, MSE: 243.60044860839844, RMSE: 15.60770478348429, R2: 0.7049240697239427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "xBDvVZpAZcPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# Define the LSTM model\n",
        "def create_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, activation='relu', input_shape=(1, 8)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "lstm_model = create_lstm_model()\n",
        "lstm_model.summary()\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_history = lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_val_lstm, y_val))\n",
        "\n",
        "# Evaluate the LSTM model\n",
        "lstm_mae, lstm_mse = lstm_model.evaluate(X_test_lstm, y_test)\n",
        "lstm_rmse = np.sqrt(lstm_mse)\n",
        "lstm_r2 = 1 - (np.sum((y_test - lstm_model.predict(X_test_lstm).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('LSTM Evaluation:')\n",
        "print(f'MAE: {lstm_mae}, MSE: {lstm_mse}, RMSE: {lstm_rmse}, R2: {lstm_r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otArvZTvZ914",
        "outputId": "02ef1915-ad5e-4a80-d1dd-1cbe54c06b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50)                11800     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11851 (46.29 KB)\n",
            "Trainable params: 11851 (46.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 4s 3ms/step - loss: 846236.3750 - mae: 576.7843 - val_loss: 703657.6250 - val_mae: 507.6960\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 678508.8125 - mae: 493.8418 - val_loss: 542865.6875 - val_mae: 447.0838\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 552001.1875 - mae: 467.4388 - val_loss: 476284.1875 - val_mae: 451.5959\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 503730.4688 - mae: 469.8664 - val_loss: 453448.6562 - val_mae: 454.7385\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 482979.3750 - mae: 467.6459 - val_loss: 440065.5312 - val_mae: 450.7759\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 470268.2500 - mae: 462.9114 - val_loss: 431224.4688 - val_mae: 446.9652\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 460295.7188 - mae: 458.2979 - val_loss: 422723.5625 - val_mae: 440.5685\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 451051.5000 - mae: 451.9965 - val_loss: 416390.5312 - val_mae: 438.4969\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 443191.3750 - mae: 448.7042 - val_loss: 411119.6562 - val_mae: 435.3534\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 436971.4688 - mae: 445.1572 - val_loss: 407110.6875 - val_mae: 434.4265\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 431744.0000 - mae: 442.9689 - val_loss: 403481.8438 - val_mae: 432.9659\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 427138.5312 - mae: 440.7738 - val_loss: 400122.4062 - val_mae: 431.1488\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 423041.3438 - mae: 439.1906 - val_loss: 396666.6875 - val_mae: 427.7650\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 419391.5938 - mae: 436.1116 - val_loss: 394244.9062 - val_mae: 427.7862\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 415954.4688 - mae: 434.8393 - val_loss: 392063.5938 - val_mae: 427.5224\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 412764.8125 - mae: 433.4099 - val_loss: 389300.4688 - val_mae: 425.2552\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 409881.0000 - mae: 432.2880 - val_loss: 386948.3438 - val_mae: 423.0630\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 407108.0000 - mae: 430.1367 - val_loss: 385538.7812 - val_mae: 424.2776\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 404548.5312 - mae: 429.0720 - val_loss: 383558.4688 - val_mae: 424.3171\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 401771.9375 - mae: 428.0930 - val_loss: 380977.9688 - val_mae: 422.0977\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 398959.5625 - mae: 426.5993 - val_loss: 378419.1250 - val_mae: 420.1983\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 396057.9062 - mae: 424.7484 - val_loss: 376155.5000 - val_mae: 419.9725\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 392956.1250 - mae: 423.7620 - val_loss: 372882.2188 - val_mae: 416.2143\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 389844.5938 - mae: 421.4607 - val_loss: 370677.4688 - val_mae: 416.2104\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 386622.1875 - mae: 419.4726 - val_loss: 367738.7812 - val_mae: 415.1249\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 383270.8438 - mae: 418.0601 - val_loss: 364727.4688 - val_mae: 413.1235\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 379824.9062 - mae: 415.9865 - val_loss: 361382.4062 - val_mae: 410.8176\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 376223.8750 - mae: 414.0923 - val_loss: 357960.1250 - val_mae: 407.9072\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 372457.7500 - mae: 411.6797 - val_loss: 354462.6250 - val_mae: 406.2914\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 368355.1562 - mae: 409.4151 - val_loss: 350102.4688 - val_mae: 402.1300\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 364157.2500 - mae: 406.2019 - val_loss: 347251.9375 - val_mae: 403.0440\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 359503.5938 - mae: 403.9559 - val_loss: 342117.9688 - val_mae: 398.5075\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 354588.9375 - mae: 400.8076 - val_loss: 337539.5625 - val_mae: 395.7165\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 349579.6875 - mae: 398.1877 - val_loss: 332775.7500 - val_mae: 391.3770\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 344575.4062 - mae: 394.5132 - val_loss: 328440.7500 - val_mae: 390.5738\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 339446.5625 - mae: 391.8476 - val_loss: 323471.6875 - val_mae: 386.0304\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 334389.7812 - mae: 388.4573 - val_loss: 319119.0938 - val_mae: 384.9255\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 329309.6250 - mae: 385.6903 - val_loss: 314208.1875 - val_mae: 380.7545\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 324301.4375 - mae: 382.2103 - val_loss: 309951.8438 - val_mae: 379.2399\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 319322.3438 - mae: 379.4981 - val_loss: 305398.3438 - val_mae: 376.5224\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 314334.5625 - mae: 376.2567 - val_loss: 300364.6875 - val_mae: 371.9603\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 309298.0000 - mae: 372.3894 - val_loss: 297930.0000 - val_mae: 374.3426\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 304468.4062 - mae: 370.5490 - val_loss: 291788.2188 - val_mae: 367.4960\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 299556.8125 - mae: 366.4179 - val_loss: 287349.2188 - val_mae: 365.6182\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 294765.2188 - mae: 363.6966 - val_loss: 282767.9062 - val_mae: 362.0635\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 289939.9062 - mae: 360.5640 - val_loss: 277582.7812 - val_mae: 357.3839\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 284999.9688 - mae: 356.9912 - val_loss: 273420.0000 - val_mae: 355.0038\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 2s 3ms/step - loss: 280259.9375 - mae: 353.8038 - val_loss: 268850.1875 - val_mae: 351.3451\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 275673.0312 - mae: 350.3649 - val_loss: 264792.9688 - val_mae: 348.8061\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 271204.5625 - mae: 347.1000 - val_loss: 260579.0469 - val_mae: 345.7687\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 257172.9531 - mae: 339.3911\n",
            "172/172 [==============================] - 1s 2ms/step\n",
            "LSTM Evaluation:\n",
            "MAE: 257172.953125, MSE: 339.39105224609375, RMSE: 18.422569100049365, R2: 0.47664891304395973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + LSTM"
      ],
      "metadata": {
        "id": "ASPsW8RAZcsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "# Define the CNN + LSTM model\n",
        "def create_cnn_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv1D(filters=16, kernel_size=2, activation='relu', padding='same'), input_shape=(8, 1, 1)))\n",
        "    model.add(TimeDistributed(Conv1D(filters=32, kernel_size=2, activation='relu', padding='same')))\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(50, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "cnn_lstm_model = create_cnn_lstm_model()\n",
        "cnn_lstm_model.summary()\n",
        "\n",
        "# Train the CNN + LSTM model\n",
        "cnn_lstm_history = cnn_lstm_model.fit(X_train_cnn_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_val_cnn_lstm, y_val))\n",
        "\n",
        "# Evaluate the CNN + LSTM model\n",
        "cnn_lstm_mae, cnn_lstm_mse = cnn_lstm_model.evaluate(X_test_cnn_lstm, y_test)\n",
        "cnn_lstm_rmse = np.sqrt(cnn_lstm_mse)\n",
        "cnn_lstm_r2 = 1 - (np.sum((y_test - cnn_lstm_model.predict(X_test_cnn_lstm).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('CNN + LSTM Evaluation:')\n",
        "print(f'MAE: {cnn_lstm_mae}, MSE: {cnn_lstm_mse}, RMSE: {cnn_lstm_rmse}, R2: {cnn_lstm_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbH_17AbaDwx",
        "outputId": "12065118-5a7a-4c2a-fa9f-87375a98556d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDist  (None, 8, 1, 16)          48        \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 8, 1, 32)          1056      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 8, 32)             0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                16600     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17755 (69.36 KB)\n",
            "Trainable params: 17755 (69.36 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 9s 8ms/step - loss: 552396.1250 - mae: 500.2258 - val_loss: 472845.0312 - val_mae: 436.2392\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 488519.5625 - mae: 479.1047 - val_loss: 440111.0000 - val_mae: 455.4450\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 456397.7812 - mae: 459.6605 - val_loss: 421664.7500 - val_mae: 437.7686\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 440843.5000 - mae: 450.1137 - val_loss: 407700.6875 - val_mae: 443.4713\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 433877.8750 - mae: 445.1046 - val_loss: 401856.0938 - val_mae: 418.6230\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 420060.8125 - mae: 436.7212 - val_loss: 399757.1875 - val_mae: 421.9202\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 8s 9ms/step - loss: 394374.0312 - mae: 420.5257 - val_loss: 366380.9375 - val_mae: 422.0446\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 9s 11ms/step - loss: 355188.1875 - mae: 400.1440 - val_loss: 329597.9062 - val_mae: 388.6521\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 8s 9ms/step - loss: 286307.0000 - mae: 359.1006 - val_loss: 225223.0156 - val_mae: 332.6225\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 232845.2656 - mae: 323.0856 - val_loss: 181393.5312 - val_mae: 294.7997\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 8s 11ms/step - loss: 182484.1250 - mae: 283.4754 - val_loss: 138909.4375 - val_mae: 253.4109\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 171436.8125 - mae: 270.6826 - val_loss: 121137.1094 - val_mae: 234.9805\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 163275.3125 - mae: 261.6177 - val_loss: 143900.7500 - val_mae: 250.4523\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 145980.0938 - mae: 246.3533 - val_loss: 116715.9766 - val_mae: 237.4402\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 139972.8906 - mae: 242.3333 - val_loss: 175773.7812 - val_mae: 281.2577\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 144221.0312 - mae: 244.4821 - val_loss: 119974.5938 - val_mae: 241.8024\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 127865.2109 - mae: 232.5083 - val_loss: 115102.3359 - val_mae: 234.1939\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 116963.1953 - mae: 222.0886 - val_loss: 118290.2578 - val_mae: 226.8622\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 131527.6094 - mae: 231.1012 - val_loss: 224913.7969 - val_mae: 289.8350\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 9s 11ms/step - loss: 146110.2188 - mae: 239.3047 - val_loss: 112038.6719 - val_mae: 232.7000\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 108698.3125 - mae: 212.9993 - val_loss: 92014.1562 - val_mae: 201.3244\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 8s 11ms/step - loss: 116717.1250 - mae: 215.2041 - val_loss: 107783.0547 - val_mae: 215.4223\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 122354.4688 - mae: 217.9218 - val_loss: 100858.3125 - val_mae: 216.7294\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 130788.0625 - mae: 223.2910 - val_loss: 146468.8125 - val_mae: 247.7157\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 112961.0391 - mae: 218.2223 - val_loss: 83064.3203 - val_mae: 192.4793\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 101128.9922 - mae: 202.9829 - val_loss: 107025.6406 - val_mae: 212.6973\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 107639.3594 - mae: 208.2331 - val_loss: 101200.7266 - val_mae: 210.2410\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 107070.0547 - mae: 205.7883 - val_loss: 84788.4766 - val_mae: 187.6123\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 9s 11ms/step - loss: 95453.8359 - mae: 193.5554 - val_loss: 96177.8125 - val_mae: 203.1454\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 117386.0312 - mae: 216.8791 - val_loss: 89555.0547 - val_mae: 190.6018\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 9s 11ms/step - loss: 97400.7109 - mae: 194.5826 - val_loss: 105683.9375 - val_mae: 217.8858\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 92446.6172 - mae: 188.6396 - val_loss: 79179.2422 - val_mae: 181.4771\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 9s 11ms/step - loss: 98166.5312 - mae: 198.1604 - val_loss: 92838.0078 - val_mae: 187.6447\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 96407.9609 - mae: 193.0950 - val_loss: 75878.9531 - val_mae: 177.6468\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 88764.1172 - mae: 184.8502 - val_loss: 82211.6641 - val_mae: 176.6703\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 97480.7891 - mae: 192.7239 - val_loss: 73388.0391 - val_mae: 174.3380\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 96469.1562 - mae: 193.7201 - val_loss: 99777.9766 - val_mae: 201.0312\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 91069.1406 - mae: 187.0927 - val_loss: 75245.9609 - val_mae: 174.5491\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 92386.6328 - mae: 186.5712 - val_loss: 194910.0156 - val_mae: 286.4581\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 114861.9688 - mae: 212.6694 - val_loss: 86370.0469 - val_mae: 190.5951\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 10s 12ms/step - loss: 85242.4062 - mae: 181.8014 - val_loss: 71986.1719 - val_mae: 167.9039\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 95408.8047 - mae: 187.6552 - val_loss: 87049.4844 - val_mae: 194.0276\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 93669.3281 - mae: 188.9304 - val_loss: 113765.3359 - val_mae: 205.7553\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 92466.0859 - mae: 190.2472 - val_loss: 93304.1484 - val_mae: 193.8321\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 89216.0000 - mae: 186.3835 - val_loss: 80845.2031 - val_mae: 174.7644\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 9s 11ms/step - loss: 82616.5469 - mae: 179.0135 - val_loss: 164658.3281 - val_mae: 255.2893\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 85574.9922 - mae: 181.9694 - val_loss: 104031.4531 - val_mae: 199.4011\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 8s 11ms/step - loss: 121833.5469 - mae: 213.4538 - val_loss: 87283.0312 - val_mae: 188.9216\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 84529.7266 - mae: 182.9638 - val_loss: 75139.3203 - val_mae: 173.6602\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 88279.3047 - mae: 186.3310 - val_loss: 85505.6719 - val_mae: 186.6398\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 84681.8906 - mae: 185.1818\n",
            "172/172 [==============================] - 1s 3ms/step\n",
            "CNN + LSTM Evaluation:\n",
            "MAE: 84681.890625, MSE: 185.1817626953125, RMSE: 13.608150597906848, R2: 0.8276709925808716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + CBAM"
      ],
      "metadata": {
        "id": "I5VepwDOZdIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Add, Activation, GlobalAveragePooling1D, GlobalMaxPooling1D, Reshape, Dense, Multiply, Concatenate\n",
        "\n",
        "# Define the CBAM block\n",
        "def cbam_block(input_tensor, ratio=8):\n",
        "    channel = input_tensor.shape[-1]\n",
        "\n",
        "    # Channel Attention\n",
        "    shared_layer_one = Dense(channel//ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
        "    shared_layer_two = Dense(channel, kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
        "\n",
        "    avg_pool = GlobalAveragePooling1D()(input_tensor)\n",
        "    avg_pool = Reshape((1, channel))(avg_pool)\n",
        "    avg_pool = shared_layer_one(avg_pool)\n",
        "    avg_pool = shared_layer_two(avg_pool)\n",
        "\n",
        "    max_pool = GlobalMaxPooling1D()(input_tensor)\n",
        "    max_pool = Reshape((1, channel))(max_pool)\n",
        "    max_pool = shared_layer_one(max_pool)\n",
        "    max_pool = shared_layer_two(max_pool)\n",
        "\n",
        "    cbam_feature = Add()([avg_pool, max_pool])\n",
        "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
        "\n",
        "    cbam_feature = Multiply()([input_tensor, cbam_feature])\n",
        "\n",
        "    # Spatial Attention\n",
        "    avg_pool = tf.reduce_mean(cbam_feature, axis=-1, keepdims=True)\n",
        "    max_pool = tf.reduce_max(cbam_feature, axis=-1, keepdims=True)\n",
        "    concat = Concatenate(axis=-1)([avg_pool, max_pool])\n",
        "    cbam_feature = Conv1D(filters=1, kernel_size=7, padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n",
        "\n",
        "    cbam_feature = Multiply()([cbam_feature, input_tensor])\n",
        "\n",
        "    return cbam_feature\n",
        "\n",
        "# Define the CNN + CBAM model\n",
        "def create_cnn_cbam_model():\n",
        "    input_tensor = tf.keras.layers.Input(shape=(8, 1))\n",
        "    x = Conv1D(filters=16, kernel_size=2, activation='relu', padding='same')(input_tensor)\n",
        "    x = cbam_block(x)\n",
        "    x = Conv1D(filters=32, kernel_size=2, activation='relu', padding='same')(x)\n",
        "    x = cbam_block(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output_tensor = Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "cnn_cbam_model = create_cnn_cbam_model()\n",
        "cnn_cbam_model.summary()\n",
        "\n",
        "# Train the CNN + CBAM model\n",
        "cnn_cbam_history = cnn_cbam_model.fit(X_train_cnn_cbam, y_train, epochs=50, batch_size=32, validation_data=(X_val_cnn_cbam, y_val))\n",
        "\n",
        "# Evaluate the CNN + CBAM model\n",
        "cnn_cbam_mae, cnn_cbam_mse = cnn_cbam_model.evaluate(X_test_cnn_cbam, y_test)\n",
        "cnn_cbam_rmse = np.sqrt(cnn_cbam_mse)\n",
        "cnn_cbam_r2 = 1 - (np.sum((y_test - cnn_cbam_model.predict(X_test_cnn_cbam).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('CNN + CBAM Evaluation:')\n",
        "print(f'MAE: {cnn_cbam_mae}, MSE: {cnn_cbam_mse}, RMSE: {cnn_cbam_rmse}, R2: {cnn_cbam_r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvpzJPoIcpBA",
        "outputId": "46de516e-2fa7-4a10-a936-e4bb776a7b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 8, 1)]               0         []                            \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 8, 16)                48        ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 16)                   0         ['conv1d_4[0][0]']            \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 16)                   0         ['conv1d_4[0][0]']            \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 16)                0         ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 1, 16)                0         ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1, 2)                 34        ['reshape[0][0]',             \n",
            "                                                                     'reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1, 16)                48        ['dense_4[0][0]',             \n",
            "                                                                     'dense_4[1][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 1, 16)                0         ['dense_5[0][0]',             \n",
            "                                                                     'dense_5[1][0]']             \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 1, 16)                0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 8, 16)                0         ['conv1d_4[0][0]',            \n",
            "                                                                     'activation[0][0]']          \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpL  (None, 8, 1)                 0         ['multiply[0][0]']            \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLa  (None, 8, 1)                 0         ['multiply[0][0]']            \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8, 2)                 0         ['tf.math.reduce_mean[0][0]', \n",
            "                                                                     'tf.math.reduce_max[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 8, 1)                 14        ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)       (None, 8, 16)                0         ['conv1d_5[0][0]',            \n",
            "                                                                     'conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 8, 32)                1056      ['multiply_1[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 32)                   0         ['conv1d_6[0][0]']            \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 32)                   0         ['conv1d_6[0][0]']            \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 1, 32)                0         ['global_average_pooling1d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)         (None, 1, 32)                0         ['global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1, 4)                 132       ['reshape_2[0][0]',           \n",
            "                                                                     'reshape_3[0][0]']           \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 1, 32)                160       ['dense_6[0][0]',             \n",
            "                                                                     'dense_6[1][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 1, 32)                0         ['dense_7[0][0]',             \n",
            "                                                                     'dense_7[1][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 1, 32)                0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)       (None, 8, 32)                0         ['conv1d_6[0][0]',            \n",
            "                                                                     'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_1 (TFO  (None, 8, 1)                 0         ['multiply_2[0][0]']          \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOp  (None, 8, 1)                 0         ['multiply_2[0][0]']          \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 8, 2)                 0         ['tf.math.reduce_mean_1[0][0]'\n",
            " )                                                                  , 'tf.math.reduce_max_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 8, 1)                 14        ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)       (None, 8, 32)                0         ['conv1d_7[0][0]',            \n",
            "                                                                     'conv1d_6[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 256)                  0         ['multiply_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 64)                   16448     ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 1)                    65        ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18019 (70.39 KB)\n",
            "Trainable params: 18019 (70.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 10s 9ms/step - loss: 558124.1250 - mae: 497.5868 - val_loss: 442638.6250 - val_mae: 456.4955\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 461514.9062 - mae: 468.0775 - val_loss: 418182.2500 - val_mae: 454.5980\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 426407.1250 - mae: 451.8540 - val_loss: 398623.1562 - val_mae: 444.3074\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 398202.3750 - mae: 434.7888 - val_loss: 373222.1250 - val_mae: 418.6693\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 383291.9375 - mae: 424.9271 - val_loss: 364739.9062 - val_mae: 419.7745\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 371470.9062 - mae: 417.5262 - val_loss: 354057.5938 - val_mae: 404.4044\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 364262.1875 - mae: 411.5736 - val_loss: 347318.3750 - val_mae: 407.2328\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 356480.5625 - mae: 406.8105 - val_loss: 339628.7500 - val_mae: 392.8647\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 348982.2500 - mae: 400.8142 - val_loss: 333172.2500 - val_mae: 388.5255\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 342473.0938 - mae: 395.2572 - val_loss: 330483.5938 - val_mae: 398.0672\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 338041.8750 - mae: 392.1173 - val_loss: 324787.8125 - val_mae: 382.4478\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 335162.1562 - mae: 389.4370 - val_loss: 319892.2500 - val_mae: 380.1505\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 330324.4062 - mae: 386.7113 - val_loss: 316645.9062 - val_mae: 387.6913\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 327668.7812 - mae: 384.8246 - val_loss: 310660.3750 - val_mae: 374.4244\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 323322.2188 - mae: 381.8618 - val_loss: 315772.1875 - val_mae: 368.7433\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 320784.5312 - mae: 379.5542 - val_loss: 303403.5000 - val_mae: 375.1643\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 318352.8750 - mae: 377.3078 - val_loss: 301370.9062 - val_mae: 367.1678\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 313061.9375 - mae: 374.7830 - val_loss: 293971.5312 - val_mae: 363.2840\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 306206.1250 - mae: 370.0977 - val_loss: 293781.4688 - val_mae: 361.9900\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 294995.7812 - mae: 362.8857 - val_loss: 270968.1562 - val_mae: 349.4557\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 280349.1875 - mae: 352.4323 - val_loss: 257506.7969 - val_mae: 336.7150\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 268490.9062 - mae: 343.9707 - val_loss: 247254.9375 - val_mae: 330.6880\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 259981.9688 - mae: 337.4153 - val_loss: 242850.2188 - val_mae: 333.1414\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 250176.7031 - mae: 330.4245 - val_loss: 234748.7344 - val_mae: 313.9195\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 244537.7500 - mae: 326.0923 - val_loss: 226737.9531 - val_mae: 312.8611\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 235779.9219 - mae: 318.1482 - val_loss: 223663.3281 - val_mae: 312.5477\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 229436.1875 - mae: 314.3560 - val_loss: 212256.0000 - val_mae: 307.5444\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 224529.1094 - mae: 311.3247 - val_loss: 205515.2656 - val_mae: 297.9785\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 219664.8594 - mae: 307.6102 - val_loss: 205040.4688 - val_mae: 300.4399\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 216105.0156 - mae: 304.9576 - val_loss: 197841.4688 - val_mae: 292.7493\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 212037.1562 - mae: 302.2103 - val_loss: 196488.3125 - val_mae: 291.6671\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 208037.9844 - mae: 298.2845 - val_loss: 192611.6406 - val_mae: 287.7042\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 205250.4531 - mae: 296.7979 - val_loss: 208571.8125 - val_mae: 300.9382\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 201493.0469 - mae: 293.4086 - val_loss: 189409.9375 - val_mae: 289.3915\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 198144.7344 - mae: 290.4844 - val_loss: 190557.5625 - val_mae: 293.4086\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 196235.3281 - mae: 288.8924 - val_loss: 185138.6406 - val_mae: 279.7137\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 192639.7500 - mae: 286.1367 - val_loss: 179686.7500 - val_mae: 281.8474\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 190131.8750 - mae: 284.9225 - val_loss: 192829.1094 - val_mae: 304.2096\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 186178.3438 - mae: 281.6968 - val_loss: 172064.0469 - val_mae: 273.7456\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 184241.8906 - mae: 279.8286 - val_loss: 170688.4844 - val_mae: 273.8229\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 181643.9219 - mae: 277.5418 - val_loss: 173796.2656 - val_mae: 273.0144\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 178203.0156 - mae: 274.8058 - val_loss: 166183.2344 - val_mae: 271.8171\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 176274.8594 - mae: 273.5360 - val_loss: 170906.7812 - val_mae: 272.9026\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 172456.6094 - mae: 270.3911 - val_loss: 156780.1719 - val_mae: 255.2765\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 170564.2344 - mae: 268.3443 - val_loss: 157623.4844 - val_mae: 257.9883\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 168475.7969 - mae: 266.5282 - val_loss: 157175.3750 - val_mae: 263.8417\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 164977.7969 - mae: 264.0563 - val_loss: 151940.9531 - val_mae: 255.8894\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 162909.6875 - mae: 261.6890 - val_loss: 152034.7812 - val_mae: 256.9655\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 161761.0938 - mae: 260.7641 - val_loss: 166720.4688 - val_mae: 277.4971\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 160444.6250 - mae: 260.5131 - val_loss: 149300.6094 - val_mae: 254.9687\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 151270.5000 - mae: 252.1145\n",
            "172/172 [==============================] - 1s 2ms/step\n",
            "CNN + CBAM Evaluation:\n",
            "MAE: 151270.5, MSE: 252.1145477294922, RMSE: 15.878115370833283, R2: 0.6921621875779941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + TRANSFORMER"
      ],
      "metadata": {
        "id": "yZ16_D5_Zd6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "import tensorflow as tf\n",
        "\n",
        "# Simplified CNN + Transformer model for testing\n",
        "def create_simple_cnn_trans_model():\n",
        "    input_tensor = tf.keras.layers.Input(shape=(8, 1))\n",
        "    x = Conv1D(filters=16, kernel_size=2, activation='relu', padding='same')(input_tensor)\n",
        "    x = Flatten()(x)\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    x = MultiHeadAttention(num_heads=2, key_dim=2)(x, x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output_tensor = Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "cnn_trans_model = create_simple_cnn_trans_model()\n",
        "cnn_trans_model.summary()\n",
        "\n",
        "\n",
        "# Train the CNN + Transformer model\n",
        "cnn_trans_history = cnn_trans_model.fit(X_train_cnn_trans, y_train, epochs=50, batch_size=32, validation_data=(X_val_cnn_trans, y_val))\n",
        "\n",
        "# Evaluate the CNN + Transformer model\n",
        "cnn_trans_mae, cnn_trans_mse = cnn_trans_model.evaluate(X_test_cnn_trans, y_test)\n",
        "cnn_trans_rmse = np.sqrt(cnn_trans_mse)\n",
        "cnn_trans_r2 = 1 - (np.sum((y_test - cnn_trans_model.predict(X_test_cnn_trans).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('CNN + Transformer Evaluation:')\n",
        "print(f'MAE: {cnn_trans_mae}, MSE: {cnn_trans_mse}, RMSE: {cnn_trans_rmse}, R2: {cnn_trans_r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBWpGmcZfQXu",
        "outputId": "97196dda-bbd3-4540-b96b-97a326f77147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 8, 1)]               0         []                            \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 8, 16)                48        ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 128)                  0         ['conv1d_8[0][0]']            \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda  (None, 1, 128)               0         ['flatten_3[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 1, 128)               2188      ['tf.expand_dims[0][0]',      \n",
            " iHeadAttention)                                                     'tf.expand_dims[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 128)                  0         ['multi_head_attention[0][0]']\n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 64)                   8256      ['flatten_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 1)                    65        ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10557 (41.24 KB)\n",
            "Trainable params: 10557 (41.24 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 526674.1250 - mae: 488.7765 - val_loss: 435905.8438 - val_mae: 448.5819\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 458085.4375 - mae: 462.8747 - val_loss: 419774.2188 - val_mae: 438.8772\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 438173.6562 - mae: 450.8920 - val_loss: 407781.7812 - val_mae: 437.4483\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 425071.7188 - mae: 446.2498 - val_loss: 401290.7188 - val_mae: 439.0368\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 410049.3438 - mae: 436.9656 - val_loss: 379273.6875 - val_mae: 413.0511\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 377822.2812 - mae: 411.8553 - val_loss: 341541.6562 - val_mae: 384.5371\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 342143.0000 - mae: 385.5093 - val_loss: 316141.9375 - val_mae: 362.7475\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 320421.6875 - mae: 373.7341 - val_loss: 298967.1250 - val_mae: 360.1382\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 302949.7812 - mae: 363.4334 - val_loss: 284283.4062 - val_mae: 365.3405\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 278491.0625 - mae: 349.5286 - val_loss: 298817.9062 - val_mae: 383.1959\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 265179.0625 - mae: 342.3140 - val_loss: 234459.2812 - val_mae: 325.4540\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 252081.1562 - mae: 333.9698 - val_loss: 232835.2500 - val_mae: 332.0946\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 245792.6875 - mae: 328.6950 - val_loss: 221263.9688 - val_mae: 317.9239\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 235784.8281 - mae: 323.3142 - val_loss: 217338.4375 - val_mae: 312.1792\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 234551.9219 - mae: 323.2282 - val_loss: 222400.3594 - val_mae: 318.3211\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 229183.2500 - mae: 319.8502 - val_loss: 228596.4844 - val_mae: 327.0400\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 225917.3594 - mae: 316.5995 - val_loss: 209520.5156 - val_mae: 312.8268\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 222174.4688 - mae: 316.1283 - val_loss: 190538.7969 - val_mae: 300.7551\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 213758.7031 - mae: 313.9982 - val_loss: 215597.7188 - val_mae: 323.0243\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 204692.0312 - mae: 308.7524 - val_loss: 186214.8594 - val_mae: 301.6306\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 202345.3125 - mae: 309.0085 - val_loss: 196446.7969 - val_mae: 312.0779\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 200384.3594 - mae: 308.8622 - val_loss: 246097.5625 - val_mae: 356.3544\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 196262.7812 - mae: 305.7332 - val_loss: 174030.9219 - val_mae: 299.0089\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 196933.8125 - mae: 306.1798 - val_loss: 168671.8594 - val_mae: 292.2219\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 185941.3125 - mae: 301.0462 - val_loss: 170194.1562 - val_mae: 292.8668\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 181502.0312 - mae: 297.7850 - val_loss: 172431.3906 - val_mae: 291.5384\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 182034.5469 - mae: 298.4076 - val_loss: 169569.5469 - val_mae: 298.0515\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 177673.6719 - mae: 295.9587 - val_loss: 155918.5312 - val_mae: 279.0300\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 177750.1406 - mae: 295.7632 - val_loss: 151575.2500 - val_mae: 275.9946\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 181453.8125 - mae: 298.9138 - val_loss: 162941.0781 - val_mae: 288.3614\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 169320.4219 - mae: 289.8471 - val_loss: 168277.0156 - val_mae: 286.6081\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 175285.0938 - mae: 293.8436 - val_loss: 152458.2188 - val_mae: 278.7423\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 166198.5156 - mae: 288.9015 - val_loss: 186783.9688 - val_mae: 305.4113\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 167083.4062 - mae: 288.7447 - val_loss: 186634.1406 - val_mae: 311.3282\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 167205.5938 - mae: 288.5637 - val_loss: 170715.0938 - val_mae: 294.4784\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 163197.5156 - mae: 285.0756 - val_loss: 149775.1562 - val_mae: 275.1684\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 164441.2812 - mae: 286.6938 - val_loss: 152652.2656 - val_mae: 277.2121\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 165227.2031 - mae: 286.8424 - val_loss: 144983.2031 - val_mae: 271.3874\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 158813.1250 - mae: 282.4156 - val_loss: 143288.5000 - val_mae: 269.5181\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 158333.9844 - mae: 281.9597 - val_loss: 165293.0469 - val_mae: 291.2981\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 160632.3906 - mae: 284.0959 - val_loss: 145369.5625 - val_mae: 273.9149\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 156827.7500 - mae: 281.1975 - val_loss: 146530.8125 - val_mae: 278.2996\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 157621.3594 - mae: 280.7667 - val_loss: 219705.8281 - val_mae: 327.3686\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 157399.2500 - mae: 280.5716 - val_loss: 150100.5312 - val_mae: 273.4910\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 153251.1406 - mae: 278.1514 - val_loss: 161951.0312 - val_mae: 280.1777\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 152134.3438 - mae: 276.6676 - val_loss: 173766.4062 - val_mae: 308.7076\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 150951.7656 - mae: 275.6530 - val_loss: 154275.7031 - val_mae: 281.8926\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 156794.5312 - mae: 281.3585 - val_loss: 139652.8750 - val_mae: 266.6317\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 152386.2031 - mae: 276.6407 - val_loss: 143254.1719 - val_mae: 269.4904\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 3s 3ms/step - loss: 153136.9688 - mae: 277.2379 - val_loss: 170359.5938 - val_mae: 296.2425\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 176275.0625 - mae: 299.8062\n",
            "172/172 [==============================] - 0s 2ms/step\n",
            "CNN + Transformer Evaluation:\n",
            "MAE: 176275.0625, MSE: 299.8062438964844, RMSE: 17.314913915364535, R2: 0.6412774432856498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + CBAM + TRANSFORMER"
      ],
      "metadata": {
        "id": "KacZXb4nZp6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN + CBAM + Transformer model\n",
        "def create_cnn_cbam_trans_model():\n",
        "    input_tensor = tf.keras.layers.Input(shape=(8, 1))\n",
        "    x = Conv1D(filters=16, kernel_size=2, activation='relu', padding='same')(input_tensor)\n",
        "    x = cbam_block(x)\n",
        "    x = Conv1D(filters=32, kernel_size=2, activation='relu', padding='same')(x)\n",
        "    x = cbam_block(x)\n",
        "    x = Flatten()(x)\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    x = MultiHeadAttention(num_heads=2, key_dim=2)(x, x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output_tensor = Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "cnn_cbam_trans_model = create_cnn_cbam_trans_model()\n",
        "cnn_cbam_trans_model.summary()\n",
        "\n",
        "# Train the CNN + CBAM + Transformer model\n",
        "cnn_cbam_trans_history = cnn_cbam_trans_model.fit(X_train_cnn_cbam_trans, y_train, epochs=50, batch_size=32, validation_data=(X_val_cnn_cbam_trans, y_val))\n",
        "\n",
        "# Evaluate the CNN + CBAM + Transformer model\n",
        "cnn_cbam_trans_mae, cnn_cbam_trans_mse = cnn_cbam_trans_model.evaluate(X_test_cnn_cbam_trans, y_test)\n",
        "cnn_cbam_trans_rmse = np.sqrt(cnn_cbam_trans_mse)\n",
        "cnn_cbam_trans_r2 = 1 - (np.sum((y_test - cnn_cbam_trans_model.predict(X_test_cnn_cbam_trans).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('CNN + CBAM + Transformer Evaluation:')\n",
        "print(f'MAE: {cnn_cbam_trans_mae}, MSE: {cnn_cbam_trans_mse}, RMSE: {cnn_cbam_trans_rmse}, R2: {cnn_cbam_trans_r2}')\n"
      ],
      "metadata": {
        "id": "eTA0tWUpfSLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb43b4be-04b2-472a-8a62-f7407f13aee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 8, 1)]               0         []                            \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 8, 16)                48        ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2  (None, 16)                   0         ['conv1d_9[0][0]']            \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Gl  (None, 16)                   0         ['conv1d_9[0][0]']            \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)         (None, 1, 16)                0         ['global_average_pooling1d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)         (None, 1, 16)                0         ['global_max_pooling1d_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 1, 2)                 34        ['reshape_4[0][0]',           \n",
            "                                                                     'reshape_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 1, 16)                48        ['dense_12[0][0]',            \n",
            "                                                                     'dense_12[1][0]']            \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 1, 16)                0         ['dense_13[0][0]',            \n",
            "                                                                     'dense_13[1][0]']            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 1, 16)                0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)       (None, 8, 16)                0         ['conv1d_9[0][0]',            \n",
            "                                                                     'activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_2 (TFO  (None, 8, 1)                 0         ['multiply_4[0][0]']          \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOp  (None, 8, 1)                 0         ['multiply_4[0][0]']          \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 8, 2)                 0         ['tf.math.reduce_mean_2[0][0]'\n",
            " )                                                                  , 'tf.math.reduce_max_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)          (None, 8, 1)                 14        ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)       (None, 8, 16)                0         ['conv1d_10[0][0]',           \n",
            "                                                                     'conv1d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)          (None, 8, 32)                1056      ['multiply_5[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3  (None, 32)                   0         ['conv1d_11[0][0]']           \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Gl  (None, 32)                   0         ['conv1d_11[0][0]']           \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)         (None, 1, 32)                0         ['global_average_pooling1d_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)         (None, 1, 32)                0         ['global_max_pooling1d_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 1, 4)                 132       ['reshape_6[0][0]',           \n",
            "                                                                     'reshape_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 1, 32)                160       ['dense_14[0][0]',            \n",
            "                                                                     'dense_14[1][0]']            \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 1, 32)                0         ['dense_15[0][0]',            \n",
            "                                                                     'dense_15[1][0]']            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 1, 32)                0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)       (None, 8, 32)                0         ['conv1d_11[0][0]',           \n",
            "                                                                     'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_3 (TFO  (None, 8, 1)                 0         ['multiply_6[0][0]']          \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOp  (None, 8, 1)                 0         ['multiply_6[0][0]']          \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 8, 2)                 0         ['tf.math.reduce_mean_3[0][0]'\n",
            " )                                                                  , 'tf.math.reduce_max_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)          (None, 8, 1)                 14        ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)       (None, 8, 32)                0         ['conv1d_12[0][0]',           \n",
            "                                                                     'conv1d_11[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 256)                  0         ['multiply_7[0][0]']          \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLamb  (None, 1, 256)               0         ['flatten_5[0][0]']           \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 1, 256)               4364      ['tf.expand_dims_1[0][0]',    \n",
            " ltiHeadAttention)                                                   'tf.expand_dims_1[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)         (None, 256)                  0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 64)                   16448     ['flatten_6[0][0]']           \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 1)                    65        ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22383 (87.43 KB)\n",
            "Trainable params: 22383 (87.43 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 14s 9ms/step - loss: 521826.4375 - mae: 491.7207 - val_loss: 431089.3438 - val_mae: 448.2490\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 437627.1875 - mae: 449.3159 - val_loss: 388905.4062 - val_mae: 431.2576\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 370512.3750 - mae: 411.3030 - val_loss: 319565.2188 - val_mae: 383.7462\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 308051.3125 - mae: 377.8608 - val_loss: 268340.7188 - val_mae: 349.6575\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 266443.4688 - mae: 351.8325 - val_loss: 238390.3594 - val_mae: 344.4350\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 221075.4375 - mae: 325.6195 - val_loss: 195627.4375 - val_mae: 321.9933\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 172554.6875 - mae: 294.1930 - val_loss: 138606.3906 - val_mae: 267.3167\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 143080.1250 - mae: 266.5750 - val_loss: 114564.3828 - val_mae: 242.0238\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 115494.0312 - mae: 242.0146 - val_loss: 105415.3125 - val_mae: 227.5318\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 107743.7734 - mae: 232.2497 - val_loss: 99513.5859 - val_mae: 220.4583\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 104993.7656 - mae: 228.7755 - val_loss: 98500.9141 - val_mae: 224.9459\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 103941.4688 - mae: 226.2943 - val_loss: 93056.1484 - val_mae: 213.9292\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 94459.8047 - mae: 216.4899 - val_loss: 91375.5469 - val_mae: 213.5174\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 96494.9844 - mae: 217.7191 - val_loss: 86896.0156 - val_mae: 203.2381\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 89575.0938 - mae: 209.8819 - val_loss: 157664.1094 - val_mae: 263.5482\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 90501.8984 - mae: 209.2501 - val_loss: 116076.8906 - val_mae: 244.8154\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 90460.9844 - mae: 210.4539 - val_loss: 92894.3438 - val_mae: 213.7233\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 82775.1016 - mae: 202.1645 - val_loss: 88628.0938 - val_mae: 210.7273\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 81206.5078 - mae: 199.9477 - val_loss: 80350.2344 - val_mae: 197.4438\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 82465.7656 - mae: 201.2348 - val_loss: 83711.1484 - val_mae: 194.8590\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 82575.0938 - mae: 202.1206 - val_loss: 81893.7969 - val_mae: 199.3306\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 83080.4688 - mae: 200.7298 - val_loss: 80726.6641 - val_mae: 200.7183\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 80425.9531 - mae: 199.3224 - val_loss: 104644.3203 - val_mae: 225.4243\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 79279.1250 - mae: 197.0280 - val_loss: 75240.8359 - val_mae: 189.5824\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 79958.4609 - mae: 197.3606 - val_loss: 79762.5859 - val_mae: 194.7694\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 73884.4531 - mae: 190.8105 - val_loss: 83162.1797 - val_mae: 197.0311\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 78956.4062 - mae: 195.6376 - val_loss: 79392.1953 - val_mae: 194.7334\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 73868.1250 - mae: 190.0577 - val_loss: 74635.6250 - val_mae: 193.1496\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 72915.3438 - mae: 188.8179 - val_loss: 76025.4922 - val_mae: 189.7906\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 71704.9844 - mae: 187.3445 - val_loss: 69550.5000 - val_mae: 187.1310\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 69063.2422 - mae: 184.1711 - val_loss: 80262.3125 - val_mae: 193.7964\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 68978.8750 - mae: 185.3003 - val_loss: 68384.8281 - val_mae: 180.5759\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 69042.2344 - mae: 184.6135 - val_loss: 69427.0781 - val_mae: 180.2203\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 8s 10ms/step - loss: 67587.5000 - mae: 181.9270 - val_loss: 75525.2422 - val_mae: 188.4494\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 68433.9453 - mae: 183.0014 - val_loss: 65228.4297 - val_mae: 179.7647\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 66305.0781 - mae: 180.1170 - val_loss: 66532.3828 - val_mae: 173.6618\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 64148.9531 - mae: 177.3444 - val_loss: 72538.7344 - val_mae: 186.3818\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 63788.3555 - mae: 176.7134 - val_loss: 72313.2656 - val_mae: 191.7844\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 69973.3672 - mae: 181.5382 - val_loss: 79840.7500 - val_mae: 203.2044\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 63044.1250 - mae: 174.9139 - val_loss: 63259.3555 - val_mae: 175.2989\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 62336.6211 - mae: 174.2318 - val_loss: 60290.3320 - val_mae: 167.1939\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 60563.1016 - mae: 170.5653 - val_loss: 65530.8672 - val_mae: 171.5669\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 62674.9570 - mae: 173.6549 - val_loss: 62084.6016 - val_mae: 172.9963\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 61266.5000 - mae: 172.1657 - val_loss: 63937.3242 - val_mae: 178.1471\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 66647.2188 - mae: 175.8222 - val_loss: 60756.2500 - val_mae: 165.9205\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 58850.4375 - mae: 168.2309 - val_loss: 63038.7930 - val_mae: 173.6900\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 58719.6562 - mae: 167.3672 - val_loss: 60876.4531 - val_mae: 168.1736\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 57657.4102 - mae: 166.4272 - val_loss: 59376.7500 - val_mae: 167.1202\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 58978.2969 - mae: 167.7301 - val_loss: 58566.9375 - val_mae: 163.4302\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 56567.5234 - mae: 164.6367 - val_loss: 57434.0195 - val_mae: 163.5456\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 53985.0938 - mae: 161.2771\n",
            "172/172 [==============================] - 1s 4ms/step\n",
            "CNN + CBAM + Transformer Evaluation:\n",
            "MAE: 53985.09375, MSE: 161.27708435058594, RMSE: 12.699491499685566, R2: 0.8901394974397558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM + TRANSFORMER"
      ],
      "metadata": {
        "id": "ikml-FzxZwlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM + Transformer model\n",
        "def create_lstm_trans_model():\n",
        "    input_tensor = tf.keras.layers.Input(shape=(1, 8))\n",
        "    x = LSTM(50, activation='relu', return_sequences=True)(input_tensor)\n",
        "    x = MultiHeadAttention(num_heads=2, key_dim=2)(x, x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output_tensor = Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "lstm_trans_model = create_lstm_trans_model()\n",
        "lstm_trans_model.summary()\n",
        "\n",
        "# Train the LSTM + Transformer model\n",
        "lstm_trans_history = lstm_trans_model.fit(X_train_lstm_trans, y_train, epochs=50, batch_size=32, validation_data=(X_val_lstm_trans, y_val))\n",
        "\n",
        "# Evaluate the LSTM + Transformer model\n",
        "lstm_trans_mae, lstm_trans_mse = lstm_trans_model.evaluate(X_test_lstm_trans, y_test)\n",
        "lstm_trans_rmse = np.sqrt(lstm_trans_mse)\n",
        "lstm_trans_r2 = 1 - (np.sum((y_test - lstm_trans_model.predict(X_test_lstm_trans).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('LSTM + Transformer Evaluation:')\n",
        "print(f'MAE: {lstm_trans_mae}, MSE: {lstm_trans_mse}, RMSE: {lstm_trans_rmse}, R2: {lstm_trans_r2}')\n"
      ],
      "metadata": {
        "id": "4qz_TQaM_JP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c376c2b-1a36-4867-87e5-5c8512390d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 1, 8)]               0         []                            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 1, 50)                11800     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 1, 50)                862       ['lstm_2[0][0]',              \n",
            " ltiHeadAttention)                                                   'lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)         (None, 50)                   0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 64)                   3264      ['flatten_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 1)                    65        ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 15991 (62.46 KB)\n",
            "Trainable params: 15991 (62.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 6s 5ms/step - loss: 531998.6250 - mae: 483.9808 - val_loss: 419387.0938 - val_mae: 434.4373\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 437119.2188 - mae: 449.1874 - val_loss: 399586.8125 - val_mae: 429.5273\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 414865.1562 - mae: 436.9590 - val_loss: 389231.0938 - val_mae: 430.0463\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 397490.4688 - mae: 427.4364 - val_loss: 378173.4062 - val_mae: 432.4532\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 373885.7812 - mae: 412.8592 - val_loss: 342901.7188 - val_mae: 394.5957\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 342303.9062 - mae: 391.9325 - val_loss: 315613.0625 - val_mae: 379.8995\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 309309.9688 - mae: 367.5912 - val_loss: 288770.1875 - val_mae: 362.2782\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 282570.8438 - mae: 347.7274 - val_loss: 260860.7500 - val_mae: 339.4568\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 256968.0781 - mae: 328.7148 - val_loss: 232172.1250 - val_mae: 312.4724\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 228952.0000 - mae: 307.7747 - val_loss: 204366.8750 - val_mae: 293.4055\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 199894.9531 - mae: 284.9818 - val_loss: 184364.4531 - val_mae: 284.3544\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 175604.3281 - mae: 268.2703 - val_loss: 159546.8594 - val_mae: 258.5402\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 159334.2031 - mae: 255.4989 - val_loss: 149020.9844 - val_mae: 243.6326\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 148619.0000 - mae: 243.8816 - val_loss: 140621.5938 - val_mae: 249.6208\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 138119.8906 - mae: 235.4888 - val_loss: 129533.8281 - val_mae: 239.8210\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 130189.4766 - mae: 228.2618 - val_loss: 116434.7500 - val_mae: 218.3832\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 4s 6ms/step - loss: 123898.6250 - mae: 224.7753 - val_loss: 111136.1016 - val_mae: 220.6616\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 120094.1172 - mae: 222.2737 - val_loss: 115509.2500 - val_mae: 222.2204\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 112958.3125 - mae: 216.3834 - val_loss: 121639.0234 - val_mae: 229.6007\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 107641.8281 - mae: 211.8280 - val_loss: 97036.0625 - val_mae: 201.8055\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 101828.5078 - mae: 206.6734 - val_loss: 90391.7344 - val_mae: 196.3074\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 95226.7266 - mae: 201.8785 - val_loss: 111019.8281 - val_mae: 218.0976\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 90987.7266 - mae: 197.1907 - val_loss: 85188.9375 - val_mae: 192.2595\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 86318.1406 - mae: 194.1410 - val_loss: 80146.9609 - val_mae: 183.6646\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 83239.0703 - mae: 191.4047 - val_loss: 79663.2734 - val_mae: 191.0507\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 79333.8438 - mae: 187.1396 - val_loss: 86395.0625 - val_mae: 199.1977\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 77571.4062 - mae: 185.7803 - val_loss: 73082.6641 - val_mae: 182.2663\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 74536.6172 - mae: 182.9921 - val_loss: 72484.2656 - val_mae: 183.5938\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 73174.9766 - mae: 182.0405 - val_loss: 69138.3828 - val_mae: 176.7169\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 70800.3125 - mae: 178.8029 - val_loss: 80778.8750 - val_mae: 194.9165\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 70662.5938 - mae: 178.2288 - val_loss: 66114.8516 - val_mae: 174.1035\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 68097.2109 - mae: 174.6928 - val_loss: 68245.8750 - val_mae: 174.1781\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 66791.1250 - mae: 173.1454 - val_loss: 64719.9727 - val_mae: 169.5472\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 67079.9453 - mae: 173.1227 - val_loss: 63537.5547 - val_mae: 169.8838\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 65012.3555 - mae: 172.8292 - val_loss: 59861.3633 - val_mae: 163.7244\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 63787.1875 - mae: 168.9082 - val_loss: 71524.0000 - val_mae: 184.5448\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 62070.6211 - mae: 167.3501 - val_loss: 58231.3516 - val_mae: 161.5457\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 60221.3203 - mae: 164.4914 - val_loss: 61246.9648 - val_mae: 168.1954\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 60132.2266 - mae: 164.0598 - val_loss: 60405.9414 - val_mae: 164.6121\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 58219.2422 - mae: 161.9040 - val_loss: 58212.8828 - val_mae: 161.9161\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 57645.4648 - mae: 161.0960 - val_loss: 54515.1328 - val_mae: 153.8400\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 57445.0156 - mae: 159.6968 - val_loss: 55258.5781 - val_mae: 157.8151\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 57326.0156 - mae: 160.3270 - val_loss: 53492.1445 - val_mae: 152.2932\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 55583.4609 - mae: 158.0368 - val_loss: 75597.8750 - val_mae: 184.3057\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 54777.8320 - mae: 157.0903 - val_loss: 56495.3438 - val_mae: 155.8804\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 55302.0312 - mae: 157.9789 - val_loss: 54604.6680 - val_mae: 156.5894\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 54891.9297 - mae: 156.6991 - val_loss: 53871.4766 - val_mae: 157.0382\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 4s 5ms/step - loss: 53624.3633 - mae: 155.4391 - val_loss: 52362.5898 - val_mae: 153.7293\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 4s 4ms/step - loss: 51964.4062 - mae: 153.9206 - val_loss: 54634.6836 - val_mae: 158.4070\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 3s 4ms/step - loss: 53072.8867 - mae: 154.9877 - val_loss: 72500.2891 - val_mae: 184.6354\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 69928.0156 - mae: 181.3048\n",
            "172/172 [==============================] - 1s 3ms/step\n",
            "LSTM + Transformer Evaluation:\n",
            "MAE: 69928.015625, MSE: 181.3048095703125, RMSE: 13.464947440310063, R2: 0.8576953789852501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + LSTM + TRANSFORMER"
      ],
      "metadata": {
        "id": "tCp7va88ZuDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN + LSTM + Transformer model\n",
        "def create_cnn_lstm_trans_model():\n",
        "    input_tensor = tf.keras.layers.Input(shape=(8, 1))\n",
        "    x = Conv1D(filters=16, kernel_size=2, activation='relu', padding='same')(input_tensor)\n",
        "    x = Conv1D(filters=32, kernel_size=2, activation='relu', padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    x = LSTM(50, activation='relu', return_sequences=True)(x)\n",
        "    x = MultiHeadAttention(num_heads=2, key_dim=2)(x, x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output_tensor = Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "cnn_lstm_trans_model = create_cnn_lstm_trans_model()\n",
        "cnn_lstm_trans_model.summary()\n",
        "\n",
        "# Train the CNN + LSTM + Transformer model\n",
        "cnn_lstm_trans_history = cnn_lstm_trans_model.fit(X_train_cnn_lstm_trans, y_train, epochs=50, batch_size=32, validation_data=(X_val_cnn_lstm_trans, y_val))\n",
        "\n",
        "# Evaluate the CNN + LSTM + Transformer model\n",
        "cnn_lstm_trans_mae, cnn_lstm_trans_mse = cnn_lstm_trans_model.evaluate(X_test_cnn_lstm_trans, y_test)\n",
        "cnn_lstm_trans_rmse = np.sqrt(cnn_lstm_trans_mse)\n",
        "cnn_lstm_trans_r2 = 1 - (np.sum((y_test - cnn_lstm_trans_model.predict(X_test_cnn_lstm_trans).flatten())**2) / np.sum((y_test - np.mean(y_test))**2))\n",
        "\n",
        "print('CNN + LSTM + Transformer Evaluation:')\n",
        "print(f'MAE: {cnn_lstm_trans_mae}, MSE: {cnn_lstm_trans_mse}, RMSE: {cnn_lstm_trans_rmse}, R2: {cnn_lstm_trans_r2}')\n"
      ],
      "metadata": {
        "id": "Y7lWUpQrhBLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7b7ccf-920c-4385-adb8-65fa07f422c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 8, 1)]               0         []                            \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)          (None, 8, 16)                48        ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 8, 32)                1056      ['conv1d_13[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 256)                  0         ['conv1d_14[0][0]']           \n",
            "                                                                                                  \n",
            " tf.expand_dims_2 (TFOpLamb  (None, 1, 256)               0         ['flatten_8[0][0]']           \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               (None, 1, 50)                61400     ['tf.expand_dims_2[0][0]']    \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 1, 50)                862       ['lstm_3[0][0]',              \n",
            " ltiHeadAttention)                                                   'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)         (None, 50)                   0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 64)                   3264      ['flatten_9[0][0]']           \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 1)                    65        ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66695 (260.53 KB)\n",
            "Trainable params: 66695 (260.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "799/799 [==============================] - 9s 7ms/step - loss: 508281.4062 - mae: 482.7639 - val_loss: 419337.4375 - val_mae: 442.7967\n",
            "Epoch 2/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 410498.4062 - mae: 430.9792 - val_loss: 338557.0625 - val_mae: 391.0516\n",
            "Epoch 3/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 301862.1250 - mae: 358.8400 - val_loss: 263043.4688 - val_mae: 331.5451\n",
            "Epoch 4/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 229676.3125 - mae: 309.7327 - val_loss: 180975.5938 - val_mae: 269.3107\n",
            "Epoch 5/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 183335.0469 - mae: 271.8852 - val_loss: 155659.0781 - val_mae: 258.4333\n",
            "Epoch 6/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 149582.2500 - mae: 245.0726 - val_loss: 133088.9688 - val_mae: 231.9877\n",
            "Epoch 7/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 126328.1172 - mae: 227.5270 - val_loss: 106952.7344 - val_mae: 205.7355\n",
            "Epoch 8/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 108458.8672 - mae: 212.5715 - val_loss: 104329.7266 - val_mae: 213.5161\n",
            "Epoch 9/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 98868.2969 - mae: 203.9717 - val_loss: 93180.5625 - val_mae: 201.0010\n",
            "Epoch 10/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 89249.3906 - mae: 196.8346 - val_loss: 82074.9922 - val_mae: 184.8016\n",
            "Epoch 11/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 81670.6172 - mae: 189.4114 - val_loss: 72580.9922 - val_mae: 178.2265\n",
            "Epoch 12/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 76098.7422 - mae: 184.0121 - val_loss: 68420.3359 - val_mae: 172.0213\n",
            "Epoch 13/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 66693.9766 - mae: 173.1769 - val_loss: 81272.4844 - val_mae: 192.0846\n",
            "Epoch 14/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 63787.2266 - mae: 169.4192 - val_loss: 67990.7969 - val_mae: 171.1986\n",
            "Epoch 15/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 65152.1289 - mae: 170.1313 - val_loss: 63010.1914 - val_mae: 168.7658\n",
            "Epoch 16/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 59198.9727 - mae: 163.1035 - val_loss: 58579.5469 - val_mae: 162.7898\n",
            "Epoch 17/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 56462.6758 - mae: 158.9661 - val_loss: 54111.9844 - val_mae: 153.9453\n",
            "Epoch 18/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 54402.2969 - mae: 154.9981 - val_loss: 54987.1680 - val_mae: 152.6756\n",
            "Epoch 19/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 49821.7695 - mae: 149.5527 - val_loss: 53991.7969 - val_mae: 151.2850\n",
            "Epoch 20/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 49576.6836 - mae: 147.8611 - val_loss: 49887.3594 - val_mae: 142.5998\n",
            "Epoch 21/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 48985.8125 - mae: 144.9999 - val_loss: 51090.1133 - val_mae: 147.5216\n",
            "Epoch 22/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 48562.1055 - mae: 145.3937 - val_loss: 49203.3047 - val_mae: 142.4799\n",
            "Epoch 23/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 46741.1016 - mae: 141.4451 - val_loss: 47285.2812 - val_mae: 139.9671\n",
            "Epoch 24/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 46067.0742 - mae: 141.2955 - val_loss: 45450.5586 - val_mae: 140.6811\n",
            "Epoch 25/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 44934.1719 - mae: 138.9350 - val_loss: 48259.7344 - val_mae: 146.3293\n",
            "Epoch 26/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 44026.6836 - mae: 137.7202 - val_loss: 50616.1523 - val_mae: 145.5851\n",
            "Epoch 27/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 43971.3125 - mae: 136.4055 - val_loss: 49680.2891 - val_mae: 145.5822\n",
            "Epoch 28/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 43634.5781 - mae: 137.0003 - val_loss: 46588.3516 - val_mae: 134.1544\n",
            "Epoch 29/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 43376.4648 - mae: 135.4198 - val_loss: 47911.7539 - val_mae: 141.8880\n",
            "Epoch 30/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 42797.3320 - mae: 134.7228 - val_loss: 44710.8594 - val_mae: 133.8687\n",
            "Epoch 31/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 42567.2578 - mae: 134.0976 - val_loss: 43246.2227 - val_mae: 131.8813\n",
            "Epoch 32/50\n",
            "799/799 [==============================] - 10s 12ms/step - loss: 41752.7852 - mae: 133.2046 - val_loss: 40232.2656 - val_mae: 127.3272\n",
            "Epoch 33/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 41323.5938 - mae: 131.6421 - val_loss: 45959.0859 - val_mae: 136.2933\n",
            "Epoch 34/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 41857.6406 - mae: 131.3260 - val_loss: 42398.1680 - val_mae: 132.0951\n",
            "Epoch 35/50\n",
            "799/799 [==============================] - 7s 8ms/step - loss: 40564.8008 - mae: 131.0968 - val_loss: 46205.0859 - val_mae: 139.1994\n",
            "Epoch 36/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 41024.8789 - mae: 131.6461 - val_loss: 44391.9297 - val_mae: 136.8760\n",
            "Epoch 37/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 40443.6484 - mae: 129.3601 - val_loss: 43026.4453 - val_mae: 132.4041\n",
            "Epoch 38/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 40200.5781 - mae: 129.6601 - val_loss: 41557.3633 - val_mae: 131.3482\n",
            "Epoch 39/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 40065.9492 - mae: 130.0978 - val_loss: 45104.3047 - val_mae: 138.5653\n",
            "Epoch 40/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 39476.4844 - mae: 128.9274 - val_loss: 40680.5742 - val_mae: 127.7001\n",
            "Epoch 41/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 38807.8320 - mae: 126.8252 - val_loss: 47361.9688 - val_mae: 140.4064\n",
            "Epoch 42/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 38056.9727 - mae: 125.9626 - val_loss: 42990.6523 - val_mae: 134.9451\n",
            "Epoch 43/50\n",
            "799/799 [==============================] - 6s 8ms/step - loss: 37994.9922 - mae: 126.2267 - val_loss: 40409.3320 - val_mae: 127.1258\n",
            "Epoch 44/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 37790.2344 - mae: 125.3948 - val_loss: 39374.7930 - val_mae: 127.7971\n",
            "Epoch 45/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 38063.7500 - mae: 125.0068 - val_loss: 41618.9062 - val_mae: 128.8217\n",
            "Epoch 46/50\n",
            "799/799 [==============================] - 5s 7ms/step - loss: 37702.1992 - mae: 124.8292 - val_loss: 37080.3125 - val_mae: 124.7158\n",
            "Epoch 47/50\n",
            "799/799 [==============================] - 6s 7ms/step - loss: 37336.4844 - mae: 124.6708 - val_loss: 44425.6953 - val_mae: 131.1746\n",
            "Epoch 48/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 38323.8984 - mae: 124.3847 - val_loss: 40536.5781 - val_mae: 128.0436\n",
            "Epoch 49/50\n",
            "799/799 [==============================] - 5s 6ms/step - loss: 36646.7109 - mae: 123.9650 - val_loss: 38086.6133 - val_mae: 121.2317\n",
            "Epoch 50/50\n",
            "799/799 [==============================] - 7s 9ms/step - loss: 36729.9883 - mae: 123.3891 - val_loss: 37680.1250 - val_mae: 122.6114\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 35076.4219 - mae: 119.2432\n",
            "172/172 [==============================] - 1s 4ms/step\n",
            "CNN + LSTM + Transformer Evaluation:\n",
            "MAE: 35076.421875, MSE: 119.24315643310547, RMSE: 10.919851484022367, R2: 0.9286189056581619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "UaiPc4fZhzg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Predict the values\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'RMSE: {rmse}')\n",
        "    print(f'R2: {r2}')\n",
        "\n",
        "    return mae, mse, rmse, r2\n"
      ],
      "metadata": {
        "id": "C9HT9pOihzg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = {\n",
        "    'Model': ['CNN', 'LSTM', 'CNN + LSTM', 'CNN + CBAM', 'CNN + Transformer', 'CNN + CBAM + Transformer', 'LSTM + Transformer', 'CNN + LSTM + Transformer'],\n",
        "    'MAE': [cnn_mae, lstm_mae, cnn_lstm_mae, cnn_cbam_mae, cnn_trans_mae, cnn_cbam_trans_mae, lstm_trans_mae, cnn_lstm_trans_mae],\n",
        "    'MSE': [cnn_mse, lstm_mse, cnn_lstm_mse, cnn_cbam_mse, cnn_trans_mse, cnn_cbam_trans_mse, lstm_trans_mse, cnn_lstm_trans_mse],\n",
        "    'RMSE': [cnn_rmse, lstm_rmse, cnn_lstm_rmse, cnn_cbam_rmse, cnn_trans_rmse, cnn_cbam_trans_rmse, lstm_trans_rmse, cnn_lstm_trans_rmse],\n",
        "    'R2': [cnn_r2, lstm_r2, cnn_lstm_r2, cnn_cbam_r2, cnn_trans_r2, cnn_cbam_trans_r2, lstm_trans_r2, cnn_lstm_trans_r2]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(result)\n",
        "results_df"
      ],
      "metadata": {
        "id": "T1mNjDdJ_8Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f22466-3fae-4051-9fa5-d82c9dbf6f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Model            MAE         MSE       RMSE        R2\n",
              "0                       CNN  144999.343750  243.600449  15.607705  0.704924\n",
              "1                      LSTM  257172.953125  339.391052  18.422569  0.476649\n",
              "2                CNN + LSTM   84681.890625  185.181763  13.608151  0.827671\n",
              "3                CNN + CBAM  151270.500000  252.114548  15.878115  0.692162\n",
              "4         CNN + Transformer  176275.062500  299.806244  17.314914  0.641277\n",
              "5  CNN + CBAM + Transformer   53985.093750  161.277084  12.699491  0.890139\n",
              "6        LSTM + Transformer   69928.015625  181.304810  13.464947  0.857695\n",
              "7  CNN + LSTM + Transformer   35076.421875  119.243156  10.919851  0.928619"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71d953ae-6d21-4d08-b62c-11e097c3ab3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>144999.343750</td>\n",
              "      <td>243.600449</td>\n",
              "      <td>15.607705</td>\n",
              "      <td>0.704924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>257172.953125</td>\n",
              "      <td>339.391052</td>\n",
              "      <td>18.422569</td>\n",
              "      <td>0.476649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN + LSTM</td>\n",
              "      <td>84681.890625</td>\n",
              "      <td>185.181763</td>\n",
              "      <td>13.608151</td>\n",
              "      <td>0.827671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN + CBAM</td>\n",
              "      <td>151270.500000</td>\n",
              "      <td>252.114548</td>\n",
              "      <td>15.878115</td>\n",
              "      <td>0.692162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN + Transformer</td>\n",
              "      <td>176275.062500</td>\n",
              "      <td>299.806244</td>\n",
              "      <td>17.314914</td>\n",
              "      <td>0.641277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN + CBAM + Transformer</td>\n",
              "      <td>53985.093750</td>\n",
              "      <td>161.277084</td>\n",
              "      <td>12.699491</td>\n",
              "      <td>0.890139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LSTM + Transformer</td>\n",
              "      <td>69928.015625</td>\n",
              "      <td>181.304810</td>\n",
              "      <td>13.464947</td>\n",
              "      <td>0.857695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CNN + LSTM + Transformer</td>\n",
              "      <td>35076.421875</td>\n",
              "      <td>119.243156</td>\n",
              "      <td>10.919851</td>\n",
              "      <td>0.928619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71d953ae-6d21-4d08-b62c-11e097c3ab3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71d953ae-6d21-4d08-b62c-11e097c3ab3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71d953ae-6d21-4d08-b62c-11e097c3ab3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64e15010-e69e-4b20-a4c1-de9708925e8a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64e15010-e69e-4b20-a4c1-de9708925e8a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64e15010-e69e-4b20-a4c1-de9708925e8a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"LSTM\",\n          \"CNN + CBAM + Transformer\",\n          \"CNN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74534.99505780397,\n        \"min\": 35076.421875,\n        \"max\": 257172.953125,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          257172.953125,\n          53985.09375,\n          144999.34375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74.12487449529829,\n        \"min\": 119.24315643310547,\n        \"max\": 339.39105224609375,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          339.39105224609375,\n          161.27708435058594,\n          243.60044860839844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5043894179097625,\n        \"min\": 10.919851484022367,\n        \"max\": 18.422569100049365,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          18.422569100049365,\n          12.699491499685566,\n          15.60770478348429\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15167990407677753,\n        \"min\": 0.47664891304395973,\n        \"max\": 0.9286189056581619,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.47664891304395973,\n          0.8901394974397558,\n          0.7049240697239427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}